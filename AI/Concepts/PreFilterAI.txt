Reality model or "world-space" is the AI program representation of external environment,(as opposed to internal space, aka "problem domain" which is the internal data/variables operated on by AI).
Accurate representation of external environment(Reality) requires vast amounts of data and input sensors, which will be mostly useless and irrelevant. To optimize the reality model, a program will only consider few critical factors and parameters at one single instant, while keep the "big data" picture for reference in some sort of database.
This presents a dillemma:
A.Either the AI will have a narrow-minded view of external space.
B.OR AI will be overwhelmed on analysis of mostly useless data.

The natural solution is to create a pre-filter program(Filter AI) which would prioritize data by relevance, and get feedback from main AI as to what data scope should be expanded or reduced(i.e. select what kind of data is needed).
Expensive MainAI functionality(reasoning, pattern recognition, analysis,etc) has to be allocated by priority, not allowing the AI itself to be stuck deciding on what trivial subjects are more important: it has to be a clear value on computation resources and relevance of data(prevent data overload).
Some may think "data overload is a human problem" but computer resources are not unlimited or infinite in time: to make fast, effective AI programs the data has to be pre-filtered and prioritized.
Unsupervised learning model simply breaks down when you allow the AI an access to (almost) unlimited data(such as internet) and the program doesn't understand the value or relevance: a reality model that contains mostly garbage and speculation will lead to equally bad performance of AI(i.e. garbage in garbage out)
